<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
<p align="center" style="font-size:30px">
<a href="https://youshye.com/">Xinyu Yang</a> , Hossein Rahmani, Sue Black, Bryan M. Williams
</p>

[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/weakly-supervised-co-training-with-swapping/weakly-supervised-semantic-segmentation-on)](https://paperswithcode.com/sota/weakly-supervised-semantic-segmentation-on?p=weakly-supervised-co-training-with-swapping)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/weakly-supervised-co-training-with-swapping/weakly-supervised-semantic-segmentation-on-4)](https://paperswithcode.com/sota/weakly-supervised-semantic-segmentation-on-4?p=weakly-supervised-co-training-with-swapping)


## Abstract
Class activation maps (CAMs) are commonly employed in weakly supervised semantic segmentation (WSSS) to produce pseudo-labels. Due to incomplete or excessive class activation, existing studies often resort to offline CAM refinement, introducing additional stages or proposing offline modules. This can cause optimization difficulties for single-stage methods and limit generalizability. In this study, we aim to reduce the observed CAM inconsistency and error to mitigate reliance on refinement processes. We propose an end-to-end WSSS model incorporating guided CAMs, wherein our segmentation model is trained while concurrently optimizing CAMs online. Our method, Co-training with Swapping Assignments (CoSA), leverages a dual-stream framework, where one sub-network learns from the swapped assignments generated by the other. We introduce three techniques: i) soft perplexity-based regularization to penalize uncertain regions; ii) a threshold-searching approach to dynamically revise the confidence threshold; and iii) contrastive separation to address the coexistence problem. CoSA demonstrates exceptional performance, achieving mIoU of 76.2% and 51.0% on VOC and COCO validation datasets, respectively, surpassing existing baselines by a substantial margin. Notably, CoSA is the first single-stage approach to outperform all existing multi-stage methods including those with additional supervision.


## Framework Overview

<img src="https://github.com/youshyee/CoSA/blob/main/assets/overview.png" alt="overview" width="1200"/>

 We propose an end-to-end dual-stream weakly-supervised segmentation framework, capable of co-optimizing the segmentation prediction and CAMs by leveraging the swapped assignments, namely CAM pseudo-labels (CPL) and segmentation pseudo-labels (SPL). Our framework comprises two networks: an assignment network (AN) and an online network (ON), where the AN is responsible for generating pseudo-labels for training the ON. While the AN has identical architecture to the ON, it is updated through exponential moving average (EMA) of the ON. The diagram on the right provides an illustration of the architecture. Given weak-augmented images as input, the AN produces CPL to supervise segmentation in the ON . During training, the CPL is softened by reliability-based adaptive weighting (RAW), formed based on CAM perplexity estimation and dynamic thresholding. The AN also generates SPL which is utilized to supervise the CAMs. Further, the CAMs are regularized to contrastively separate the foreground from the background regions . Note that the ON is also trained for classification using the image-level class labels.

## SPL-guided CAMs

![oracle](oracle.png)

## CPL Analysis

![cpl](cpl.png)

##  Coexistence Problem

![coex](coex.png)

## Comparison with SOTA

On COCO dataset:
<img src="https://github.com/youshyee/CoSA/blob/main/assets/coco1.png" alt="overview" width="1200"/>
<img src="https://github.com/youshyee/CoSA/blob/main/assets/coco2.png" alt="overview" width="1200"/>

On VOC dataset:
<img src="https://github.com/youshyee/CoSA/blob/main/assets/voc1.png" alt="overview" width="1200"/>

## Paper

[PDF](https://youshyee.com/pdfs/CoSA.pdf)
[Poster](./conference_poster.pdf)
[ArXiv](https://arxiv.org/abs/2402.17891)


## Bibtex

```markdown
@misc{yang2021dcldet,
      title={Dynamic Curriculum Learning for Great Ape Detection in the Wild},
      author={Xinyu Yang and Tilo Burghardt and Majid Mirmehdi},
      year={2022},
      eprint={2205.00275},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Acknowledgements

We would like to thank the entire team of the Pan
African Programme: ‘The Cultured Chimpanzee’ MaxPlanck-Institute (2022) and its collaborators for allowing the use of their data for this project. Please contact the copyright holder Pan African Programme at
http://panafrican.eva.mpg.de to obtain the source
videos from the dataset. Particularly, we thank: H
Kuehl, C Boesch, M Arandjelovic, and P Dieguez. We
would also like to thank: K Zuberbuehler, K Corogenes,
E Normand, V Vergnes, A Meier, J Lapuente, D Dowd,
S Jones, V Leinert, EWessling, H Eshuis, K Langergraber, S Angedakin, S Marrocoli, K Dierks, T C Hicks,
J Hart, K Lee, and M Murai. Thanks also to the team
at https://www.chimpandsee.org. The work that allowed for the collection of the dataset was funded by
the Max Planck Society, Max Planck Society Innovation
Fund, and Heinz L. Krekeler. In this respect we would
also like to thank: Foundation Ministre de la Recherche
Scientifique, and Ministre des Eaux et For lts in Cote
d’Ivoire; Institut Congolais pour la Conservation de la
Nature and Ministre de la Recherch Scientifique in DR
Congo; Forestry Development Authority in Liberia; Direction des Eaux, For lts Chasses et de la Conservation
des Sols, Senegal; and Uganda National Council for Science and Technology, Uganda Wildlife Authority, National Forestry Authority in Uganda.
